{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization\n",
    "from keras.layers.core import Dropout\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from glob import glob\n",
    "import re\n",
    "import os.path\n",
    "import scipy.misc\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from skimage.measure import moments_hu\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "namefile = 'Unet_Cabeza_Mano'\n",
    "image_shape = (160, 320)  \n",
    "data_dir = './manos'\n",
    "batch_size = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(data_folder, image_shape, batch_size):\n",
    "    \"\"\"  Create batches of training and validation data \"\"\"\n",
    "    image_paths = glob(os.path.join(data_folder, 'images', '*.png'))\n",
    "    label_paths = {\n",
    "        re.sub(r'_(lane|road)_', '_', os.path.basename(path)): path\n",
    "        for path in glob(os.path.join(data_folder, 'labels', '*.png'))}\n",
    "    \n",
    "    background_color = np.array([0.9, 0.9, 0.9])  ## Solo el blanco\n",
    "\n",
    "    random.shuffle(image_paths)\n",
    "    while 1: \n",
    "        for batch_i in range(0, len(image_paths), batch_size):\n",
    "            images = []\n",
    "            gt_images = []\n",
    "            for image_file in image_paths[batch_i:batch_i+batch_size]:\n",
    "                gt_image_file = label_paths[os.path.basename(image_file)]\n",
    "\n",
    "                image = resize(imageio.imread(image_file), image_shape, mode='constant',anti_aliasing=False)\n",
    "                gt_image = resize(imageio.imread(gt_image_file), image_shape, mode='constant', anti_aliasing=False)\n",
    "\n",
    "                \n",
    "                gt_bg = np.all(gt_image >= background_color, axis=2)  #Binarizar la segmentación del target\n",
    "                gt_bg = gt_bg.reshape(*gt_bg.shape, 1)   # Añadirle una dimensión al tensor\n",
    "                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)  #crear dos capas reflejo\n",
    "                \n",
    "                images.append(image)\n",
    "                gt_images.append(gt_image)\n",
    "                \n",
    "            X = np.array(images)\n",
    "            Y = np.array(gt_images)\n",
    "            yield (X, Y)\n",
    "        \n",
    "train_generator = generator(os.path.join(data_dir, 'training'), image_shape, batch_size)\n",
    "validation_generator = generator(os.path.join(data_dir, 'validation'), image_shape, batch_size)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file ='./manos/training/images/LSM2740_65.png'\n",
    "gt_image_file ='./manos/training/labels/LSM2740_65.png'\n",
    "\n",
    "image = resize(imageio.imread(image_file), image_shape, mode='constant',anti_aliasing=False)\n",
    "gt_image = resize(imageio.imread(gt_image_file), image_shape, mode='constant', anti_aliasing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gt_image.shape)\n",
    "background_color = np.array([0.9, 0.9, 0.9])  ## Solo el blanco\n",
    "gt_bg = np.all(gt_image >= background_color, axis=2)\n",
    "print(gt_bg.shape)\n",
    "gt_bg = gt_bg.reshape(*gt_bg.shape, 1)\n",
    "print(gt_bg.shape)\n",
    "gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)\n",
    "print(gt_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_gen_args = dict(featurewise_center=True\n",
    "                     )\n",
    "image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "mask_datagen = ImageDataGenerator(**data_gen_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 29 images belonging to 2 classes.\n",
      "Found 29 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "seed = 1\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    'manos1/training/images',\n",
    "     target_size=image_shape,\n",
    "     class_mode='input',\n",
    "     seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    'manos1/training/labels',\n",
    "    target_size=image_shape,\n",
    "    class_mode='input',\n",
    "    seed=seed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = zip(image_generator, mask_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función de validación\n",
    "def IOU_calc(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(K.clip(y_true_f + y_pred_f, 0, 1))\n",
    "    return intersection/union\n",
    "\n",
    "\n",
    "def IOU_calc_loss(y_true, y_pred):\n",
    "    return -IOU_calc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo de Unet \n",
    "def unet02(img_rows, img_cols, img_channels):  #lr = 0.0009\n",
    "    x = Input(shape=(img_rows, img_cols, img_channels))\n",
    "    \n",
    "    # Encoder \n",
    "    conv1 = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    conv2 = Conv2D(64, (1, 1), padding='same', activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), padding='same', activation='relu')(pool1)\n",
    "    conv4 = Conv2D(128, (1, 1), padding='same', activation='relu')(conv3)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(256, (3, 3), padding='same', activation='relu')(pool2)\n",
    "    conv6 = Conv2D(256, (1, 1), padding='same', activation='relu')(conv5)\n",
    "    \n",
    "    # Decoder   \n",
    "    convT1 = Conv2D(128, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge1 = concatenate([convT1, conv4], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), padding='same', activation='relu')(merge1)\n",
    "    conv8 = Conv2D(128, (1, 1), padding='same', activation='relu')(conv7)\n",
    "    \n",
    "    convT2 = Conv2D(64, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge2 = concatenate([convT2, conv2], axis=3)\n",
    "    conv9 = Conv2D(64, (3, 3), padding='same', activation='relu')(merge2)\n",
    "    conv10 = Conv2D(64, (1, 1), padding='same', activation='relu')(conv9)  \n",
    "\n",
    "    # Segmentation\n",
    "    y = Conv2D(2, (1, 1), activation='softmax')(conv10)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 100, 124, 128), (None, 100, 125, 128)]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-a3cdc2771de9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munet02\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mimage_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-2-a7e9ddc90c92>\u001b[0m in \u001b[0;36munet02\u001b[1;34m(img_rows, img_cols, img_channels)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Decoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mconvT1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mUpSampling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mmerge1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mconvT1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconv4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m     \u001b[0mconv7\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mconv8\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'same'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconv7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(inputs, axis, **kwargs)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconcatenation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minputs\u001b[0m \u001b[0malongside\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m     \"\"\"\n\u001b[1;32m--> 641\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mConcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, **kwargs)\u001b[0m\n\u001b[0;32m    429\u001b[0m                                          \u001b[1;34m'You can build it manually via: '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    430\u001b[0m                                          '`layer.build(batch_input_shape)`')\n\u001b[1;32m--> 431\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munpack_singleton\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    432\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\TensorFlow\\lib\\site-packages\\keras\\layers\\merge.py\u001b[0m in \u001b[0;36mbuild\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    352\u001b[0m                              \u001b[1;34m'inputs with matching shapes '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m                              \u001b[1;34m'except for the concat axis. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m                              'Got inputs shapes: %s' % (input_shape))\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_merge_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: A `Concatenate` layer requires inputs with matching shapes except for the concat axis. Got inputs shapes: [(None, 100, 124, 128), (None, 100, 125, 128)]"
     ]
    }
   ],
   "source": [
    "model = unet02(image_shape[0],image_shape[1],3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Luis\\Anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Luis\\Anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Luis\\Anaconda3\\envs\\TF\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Epoch 1/2\n",
      "150/200 [=====================>........] - ETA: 27s - loss: 0.0994 - IOU_calc: 0.8925"
     ]
    }
   ],
   "source": [
    "#fase de entrenamineto\n",
    "\n",
    "model = unet02(image_shape[0],image_shape[1],3)\n",
    "adam = optimizers.Adam(lr=0.00009, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[IOU_calc])\n",
    "checkpointer = ModelCheckpoint(filepath='bestmodel_' + namefile + '.h5', monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                              mode='min', period=1)\n",
    "h = model.fit_generator(train_generator, steps_per_epoch=200, epochs=2, verbose=1, callbacks=[checkpointer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graficas del entrenamiento\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (5,4) # Hacer las figuras más grandes\n",
    "epoch_max = np.argmax(h.history['val_IOU_calc'])\n",
    "plt.plot(h.history['val_IOU_calc'], label='IOUval')\n",
    "plt.plot(h.history['IOU_calc'], label='IOUtrain')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot(epoch_max, h.history['val_IOU_calc'][epoch_max],'*')\n",
    "plt.xlabel('epochs', fontsize=24)\n",
    "plt.ylabel('IOU', fontsize=24)\n",
    "plt.suptitle('Curvas de aprendizaje', fontsize=30)\n",
    "plt.savefig('IOU_bestmodel_' + namefile + '.pdf', bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "epoch_max = np.argmin(h.history['val_loss'])\n",
    "plt.plot(h.history['val_loss'], label='CEval')\n",
    "plt.plot(h.history['loss'], label='CE')\n",
    "plt.legend(loc='upper right')\n",
    "plt.plot(epoch_max, h.history['val_loss'][epoch_max],'*')\n",
    "plt.xlabel('epochs', fontsize=24)\n",
    "plt.ylabel('cross entropy', fontsize=24)\n",
    "plt.suptitle('Curvas de aprendizaje', fontsize=30)\n",
    "plt.savefig('CE_bestmodel_' + namefile + '.pdf', bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el mejor modelo\n",
    "model.load_weights('bestmodel_' + namefile + '.h5')\n",
    "\n",
    "score_train = model.evaluate_generator(train_generator, steps=89//batch_size)\n",
    "print('training', score_train)\n",
    "score_val = model.evaluate_generator(validation_generator, steps=89//batch_size)\n",
    "print('validation', score_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Muestra algunos resultados de la fase de entrenamiento\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15,15) # Hacer las figuras más grandes\n",
    "data_folder = './manos/validation/images'\n",
    "th_segment = 0.5\n",
    "k = 10\n",
    "filelist = glob(os.path.join(data_folder, '*.png'))\n",
    "random.shuffle(filelist)\n",
    "i = 1\n",
    "for image_file in filelist[0:k]:\n",
    "    img_original = imageio.imread(image_file)\n",
    "    img = resize(img_original, image_shape, mode = 'constant')\n",
    "    y = model.predict(np.expand_dims(img, axis=0), batch_size=1)\n",
    "    #print (y.shape)\n",
    "    mask = np.stack([y[0,:,:,0] > th_segment,np.zeros(image_shape),np.zeros(image_shape)], axis=2)\n",
    "    masked = np.ma.masked_array(mask, img).astype('float32')\n",
    "    #print (masked.shape)\n",
    "    #print (masked.dtype)\n",
    "    plt.subplot(5,2,i)\n",
    "    plt.imshow(img,interpolation='none') \n",
    "    plt.imshow(masked, interpolation='none', alpha=0.35) \n",
    "    plt.tick_params(axis='both',which='both',bottom=False, left=False,labelbottom=False,labelleft=False) \n",
    "    i += 1\n",
    "#plt.savefig('photos_bestmodel_2' + namefile +'.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar un Modelo\n",
    "from keras.models import load_model\n",
    "model = load_model('bestmodel_' + namefile + '.h5', custom_objects={'IOU_calc': IOU_calc}) # se carga el modelo completo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargar una imagen y realizar procesamiento para la entrada del Modelo\n",
    "image_file1 = './manos/validation/images/S1.jpg'\n",
    "img_original = imageio.imread(image_file1)\n",
    "img = resize(img_original, image_shape ,mode = 'constant')\n",
    "\n",
    "img1 = np.expand_dims(img, axis=0)\n",
    "img1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se cre una función para ver ciertas capas de pendiendo de una entrada\n",
    "from keras import backend as K\n",
    "\n",
    "# with a Sequential model\n",
    "get_3rd_layer_output = K.function([model.layers[0].input],\n",
    "                                  [model.layers[6].output])\n",
    "\n",
    "layer_output = get_3rd_layer_output([img1]) # img1 es la imagen de entrada, se introduce al modelo\n",
    "ji = layer_output[0] #se optiene la lista de salida de la capa\n",
    "\n",
    "print(ji.shape[3])\n",
    "\n",
    "#plt.matshow(ji[0,:,:,12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se muestran  filtros dentro de la capa seleccionada\n",
    "plt.rcParams['figure.figsize'] = (15,15) # Hacer las figuras más grandes\n",
    "arr = np.arange(ji.shape[3])\n",
    "np.random.shuffle(arr)\n",
    "g=1\n",
    "for i in arr[0:10]:\n",
    "    \n",
    "    plt.subplot(5,2,g)\n",
    "    plt.imshow(ji[0,:,:,i],cmap='gray') \n",
    "   \n",
    "    plt.title('número de filtro'+' '+ str(i), fontsize=20)\n",
    "    plt.tick_params(axis='both',which='both',bottom=False, left=False,labelbottom=False,labelleft=False) \n",
    "    g += 1\n",
    "plt.savefig('fotos_filtros' + namefile +'.pdf', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_segment = 0.5\n",
    "y1 = model.predict(img1, batch_size=1)\n",
    "#print (y.shape)\n",
    "mask1 = np.stack([y1[0,:,:,0] > th_segment,np.zeros(image_shape),np.zeros(image_shape)], axis=2)\n",
    "masked1 = np.ma.masked_array(mask1, img).astype('float32')\n",
    "plt.imshow(img,interpolation='none') \n",
    "plt.imshow(masked1, interpolation='none', alpha=0.55) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
