{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, concatenate, Conv2D, MaxPooling2D, UpSampling2D\n",
    "import math\n",
    "import imageio\n",
    "from skimage.transform import resize\n",
    "from keras.models import Model\n",
    "from glob import glob\n",
    "import os.path\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import optimizers\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras.backend as K\n",
    "\n",
    "ImageDims = (160, 320)\n",
    "DatasetDir = 'D:\\OpenVINO\\PH2'\n",
    "RsltDir = 'D:\\OpenVINO\\\\Res2'\n",
    "ImageExt = '.bmp'\n",
    "batch_size = 5\n",
    "ModelArch = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImBinarize(Image, Color):\n",
    "    if len(Image.shape) < 3:\n",
    "        x = np.zeros((Image.shape[0], Image.shape[1], 3))\n",
    "        x[:,:,1] = Image\n",
    "        x[:,:,2] = Image\n",
    "        x[:,:,0] = Image                    \n",
    "        return np.all(x == Color, axis = 2)  #Binarizar la segmentaci칩n del target\n",
    "    else:\n",
    "        return np.all(Image == Color, axis = 2)  #Binarizar la segmentaci칩n del target\n",
    "\n",
    "def generator(data_folder, image_shape, batch_size):\n",
    "    ImagePaths = glob(os.path.join(data_folder, 'images', '*' + ImageExt))    \n",
    "    label_paths = {\n",
    "        os.path.basename(path): path\n",
    "        for path in glob(os.path.join(data_folder, 'labels', '*' + ImageExt))}\n",
    "    \n",
    "    background_color = np.array([1.0, 1.0, 1.0])  ## Solo el blanco\n",
    "\n",
    "    random.shuffle(ImagePaths)\n",
    "    while 1: \n",
    "        for batch_i in range(0, len(ImagePaths), batch_size):\n",
    "            images = []\n",
    "            gt_images = []\n",
    "            for image_file in ImagePaths[batch_i:batch_i+batch_size]:\n",
    "                gt_image_file = label_paths[os.path.basename(image_file)]\n",
    "\n",
    "                image = resize(imageio.imread(image_file), image_shape, mode='constant', anti_aliasing=False)\n",
    "                gt_image = resize(imageio.imread(gt_image_file), image_shape, mode='constant', anti_aliasing=False)\n",
    "                gt_bg = ImBinarize(gt_image, background_color)                \n",
    "                \n",
    "                gt_bg = gt_bg.reshape(*gt_bg.shape, 1)   # A침adirle una dimensi칩n al tensor\n",
    "                \n",
    "                gt_image = np.concatenate((gt_bg, np.invert(gt_bg)), axis=2)  #crear dos capas reflejo\n",
    "                \n",
    "                images.append(image)\n",
    "                gt_images.append(gt_image)\n",
    "                \n",
    "            X = np.array(images)\n",
    "            Y = np.array(gt_images)\n",
    "            yield (X, Y)\n",
    "        \n",
    "train_generator = generator(os.path.join(DatasetDir, 'training'), ImageDims, batch_size)\n",
    "validation_generator = generator(os.path.join(DatasetDir, 'validation'), ImageDims, batch_size)      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IOU_calc(y_true, y_pred):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(K.clip(y_true_f + y_pred_f, 0, 1))\n",
    "    return intersection/union\n",
    "\n",
    "def IOU_calc_loss(y_true, y_pred):\n",
    "    return -IOU_calc(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def UNetFull(img_rows, img_cols, img_channels):  # 23 trainable layers, use same padding, en lugar de unpadding layers\n",
    "    x = Input(shape=(img_rows, img_cols, img_channels))\n",
    "    \n",
    "    # Encoder \n",
    "    conv1 = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    conv2 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), padding='same', activation='relu')(pool1)\n",
    "    conv4 = Conv2D(128, (3, 3), padding='same', activation='relu')(conv3)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(256, (3, 3), padding='same', activation='relu')(pool2)\n",
    "    conv6 = Conv2D(256, (3, 3), padding='same', activation='relu')(conv5)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv6)\n",
    "    \n",
    "    conv7 = Conv2D(512, (3, 3), padding='same', activation='relu')(pool3)\n",
    "    conv8 = Conv2D(512, (3, 3), padding='same', activation='relu')(conv7)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv8)\n",
    "    \n",
    "    conv9 = Conv2D(1024, (3, 3), padding='same', activation='relu')(pool4)\n",
    "    conv10 = Conv2D(1024, (3, 3), padding='same', activation='relu')(conv9)\n",
    "    \n",
    "    # Decoder\n",
    "    convT1 = Conv2D(512, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv10))\n",
    "    merge1 = concatenate([convT1, conv8], axis=3)\n",
    "    conv11 = Conv2D(512, (3, 3), padding='same', activation='relu')(merge1)\n",
    "    conv12 = Conv2D(512, (3, 3), padding='same', activation='relu')(conv11)\n",
    "    \n",
    "    convT2 = Conv2D(256, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv12))\n",
    "    merge2 = concatenate([convT2, conv6], axis=3)\n",
    "    conv13 = Conv2D(256, (3, 3), padding='same', activation='relu')(merge2)\n",
    "    conv14 = Conv2D(256, (3, 3), padding='same', activation='relu')(conv13)\n",
    "    \n",
    "    convT3 = Conv2D(128, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv14))\n",
    "    merge3 = concatenate([convT3, conv4], axis=3)\n",
    "    conv15 = Conv2D(128, (3, 3), padding='same', activation='relu')(merge3)\n",
    "    conv16 = Conv2D(128, (3, 3), padding='same', activation='relu')(conv15)\n",
    "    \n",
    "    convT4 = Conv2D(64, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv16))\n",
    "    merge4 = concatenate([convT4, conv2], axis=3)\n",
    "    conv17 = Conv2D(64, (3, 3), padding='same', activation='relu')(merge4)\n",
    "    conv18 = Conv2D(64, (3, 3), padding='same', activation='relu')(conv17)\n",
    "\n",
    "    y = Conv2D(2, (1, 1), activation='softmax')(conv18)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)\n",
    "\n",
    "def UNetMedium(img_rows, img_cols, img_channels):  #lr = 0.0009\n",
    "    x = Input(shape=(img_rows, img_cols, img_channels))\n",
    "    \n",
    "    # Encoder \n",
    "    conv1 = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    conv2 = Conv2D(64, (1, 1), padding='same', activation='relu')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), padding='same', activation='relu')(pool1)\n",
    "    conv4 = Conv2D(128, (1, 1), padding='same', activation='relu')(conv3)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "    \n",
    "    conv5 = Conv2D(256, (3, 3), padding='same', activation='relu')(pool2)\n",
    "    conv6 = Conv2D(256, (1, 1), padding='same', activation='relu')(conv5)\n",
    "    \n",
    "    # Decoder   \n",
    "    convT1 = Conv2D(128, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv6))\n",
    "    merge1 = concatenate([convT1, conv4], axis=3)\n",
    "    conv7 = Conv2D(128, (3, 3), padding='same', activation='relu')(merge1)\n",
    "    conv8 = Conv2D(128, (1, 1), padding='same', activation='relu')(conv7)\n",
    "    \n",
    "    convT2 = Conv2D(64, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv8))\n",
    "    merge2 = concatenate([convT2, conv2], axis=3)\n",
    "    conv9 = Conv2D(64, (3, 3), padding='same', activation='relu')(merge2)\n",
    "    conv10 = Conv2D(64, (1, 1), padding='same', activation='relu')(conv9)  \n",
    "\n",
    "    # Segmentation\n",
    "    y = Conv2D(2, (1, 1), activation='softmax')(conv10)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)\n",
    "\n",
    "def UNetSmall(img_rows, img_cols, img_channels):  #lr = 0.0009\n",
    "    x = Input(shape=(img_rows, img_cols, img_channels))\n",
    "    \n",
    "    # Encoder \n",
    "    conv1 = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    conv2 = Conv2D(64, (1, 1), padding='same', activation='relu')(conv1)\n",
    "    pool = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    conv3 = Conv2D(128, (3, 3), padding='same', activation='relu')(pool)\n",
    "    conv4 = Conv2D(128, (1, 1), padding='same', activation='relu')(conv3)\n",
    "    \n",
    "    # Decoder   \n",
    "    convT = Conv2D(64, (2, 2), padding='same', activation='relu')(UpSampling2D(size=(2, 2))(conv4))\n",
    "    merge = concatenate([convT, conv2], axis=3)\n",
    "    conv5 = Conv2D(64, (3, 3), padding='same', activation='relu')(merge)\n",
    "    conv6 = Conv2D(64, (1, 1), padding='same', activation='relu')(conv5)\n",
    "    \n",
    "    # Segmentation\n",
    "    y = Conv2D(2, (1, 1), activation='softmax')(conv6)\n",
    "\n",
    "    return Model(inputs=x, outputs=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Epochs = 2;\n",
    "FileName = str(ModelArch) +'A_' + str(Epochs) + 'E_' + str(ImageDims[0]) + 'x' + str(ImageDims[1]) + 'D.h5'\n",
    "\n",
    "if ModelArch == 0:\n",
    "    model = UNetFull(ImageDims[0], ImageDims[1], 3)\n",
    "elif ModelArch == 1:\n",
    "    model = UNetMedium(ImageDims[0], ImageDims[1], 3)\n",
    "else:\n",
    "    model = UNetSmall(ImageDims[0], ImageDims[1], 3)\n",
    "\n",
    "adam = optimizers.Adam(lr = 0.0009, beta_1 = 0.9, beta_2 = 0.999, epsilon = 1e-08, decay = 0.0)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=[IOU_calc])\n",
    "checkpointer = ModelCheckpoint(filepath = RsltDir + '\\\\' + FileName, monitor='val_loss', verbose=0, save_best_only=True,\n",
    "                              mode = 'min', period = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "h = model.fit_generator(train_generator, steps_per_epoch=40, epochs = Epochs, verbose=1, callbacks=[checkpointer], \n",
    "                        validation_data=validation_generator, validation_steps=89//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = (12, 4) # Hacer las figuras m치s grandes\n",
    "\n",
    "BestIOU = np.argmax(h.history['val_IOU_calc'])\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(h.history['val_IOU_calc'], label='Validation')\n",
    "plt.plot(h.history['IOU_calc'], label='Training')\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot(BestIOU, h.history['val_IOU_calc'][BestIOU],'go')\n",
    "plt.plot(BestIOU, h.history['IOU_calc'][BestIOU],'go')\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.ylabel('IOU', fontsize=20)\n",
    "plt.suptitle('Learning curves', fontsize=28)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "BestCE = np.argmin(h.history['val_loss'])\n",
    "plt.plot(h.history['val_loss'], label='Validation')\n",
    "plt.plot(h.history['loss'], label='Training')\n",
    "plt.legend(loc='upper right')\n",
    "plt.plot(BestCE, h.history['val_loss'][BestCE],'go')\n",
    "plt.plot(BestCE, h.history['loss'][BestCE],'go')\n",
    "plt.xlabel('Epoch', fontsize=20)\n",
    "plt.ylabel('Cross Entropy', fontsize=20)\n",
    "\n",
    "plt.savefig(RsltDir + '\\\\IOU_CE_' + FileName + '.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainScore = model.evaluate_generator(train_generator, steps=89//batch_size)\n",
    "ValidationScore = model.evaluate_generator(validation_generator, steps=89//batch_size)\n",
    "file = open(RsltDir + '\\\\BestModelAssess_' + FileName + '.txt', 'w') \n",
    "file.write('Training\\n')\n",
    "for Value in TrainScore:\n",
    "    file.write(str(Value) + '\\n') \n",
    "file.write('Validation\\n')\n",
    "for Value in ValidationScore:\n",
    "    file.write(str(Value) + '\\n')\n",
    "file.close()\n",
    "print('Model assess saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
