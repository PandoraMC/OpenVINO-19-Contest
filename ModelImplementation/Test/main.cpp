#include <dirent.h>
#include <iostream>
#include <ctype.h>
#include <opencv2/core.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <iterator>
#include <time.h>
#include <stdlib.h>
#include <vector>
#include <memory>
#include <string>
#include <samples/common.hpp>
#include <math.h>

#include <inference_engine.hpp>
#include <ext_list.hpp>

#define DIR_OFFSET 2

using namespace cv;
using namespace std;
using namespace InferenceEngine;

typedef chrono::high_resolution_clock Time;
typedef chrono::duration<double, ratio<1, 1000>> ms;
typedef chrono::duration<float> fsec;

list<string> getFileNames(char* strDirectory);
void configModelInterfaces(CNNNetwork Model, string *inLayerName, string *outLayerName);
CNNNetwork ReadModel(char* modelDir, char *modelName);
string getListFileName(list<string> FileNames, int index);
char* getDirectory(char** argv, int value);
char* composeFilePath(char* path, char* file, char* ext);
Mat composeClassSeg(Blob::Ptr ptrBlobProb);
Mat colorObjective(Mat imageMat, Mat classMat, Scalar colorMask, float alpha, int objetive);
int getClass(Blob::Ptr ptrBlobProb);
Mat getObjective(Mat Classes, int obj);
void drawFeatures(Mat refImage, Mat binImage, float *Ecc, int *Area);
void measure(InferRequest Infer, string id);
static UNUSED Blob::Ptr wrapMat2Blob(const Mat &mat);


int main(int argc, char** argv){
	string lblClasses[3] = {"Common Nevus", "Atypical Nevus", "Melanoma"};
	int fileNumber, filesAvailable;
	string fileName, inSegLayerName, inClassLayerName, outSegLayerName, outClassLayerName;
	srand(time(NULL));
	char *imageDir = getDirectory(argv, 1);
	list<string> lstFileNames = getFileNames(imageDir);
	filesAvailable = lstFileNames.size() - DIR_OFFSET;
	cout << "Image directory " << imageDir << " with " << filesAvailable << " files available" << endl;
	char *modelDir = getDirectory(argv, 2);
	char *SegModelName = *(argv + 3);
	char *ClassModelName = *(argv + 4);
	string device = *(argv + 5);
	Mat inImage, outImage;
	cout << "Segmentation model path: " << modelDir << SegModelName << ".*" << endl;	
	cout << "Classification model path: " << modelDir << ClassModelName << ".*" << endl;
	// 1. Load inference Engine instance
	Core InfEngine;
	CNNNetwork SegNet, ClassNet;
	ExecutableNetwork SegExcNet, ClassExcNet;
	InferRequest SegInfRequest, ClassInfRequest;
	try{
		
		if(!device.compare("CPU"))
			InfEngine.AddExtension(make_shared<Extensions::Cpu::CpuExtensions>(), "CPU");
		cout << "Device:" << endl << InfEngine.GetVersions(device) << endl;
		// 2. Read IR Generated by ModelOptimizer (.xml and .bin files)
		SegNet = ReadModel(modelDir, SegModelName);	
		ClassNet = ReadModel(modelDir, ClassModelName);

		QueryNetworkResult SegRes = InfEngine.QueryNetwork(SegNet, device, { });
		QueryNetworkResult ClassRes = InfEngine.QueryNetwork(ClassNet, device, { });

		SegRes.supportedLayersMap["layerName"] = "CPU";
		ClassRes.supportedLayersMap["layerName"] = "CPU";

		for (auto && layer : SegRes.supportedLayersMap)
			if(layer.first.compare("layerName"))
				SegNet.getLayerByName(layer.first.c_str())->affinity = layer.second;

		for (auto && layer : ClassRes.supportedLayersMap)
			if(layer.first.compare("layerName"))
				ClassNet.getLayerByName(layer.first.c_str())->affinity = layer.second;

		// 3. Configure input & output
		// 3.1 Input configuration. Mark input as resizable by setting of a resize algorithm.
		configModelInterfaces(SegNet, &inSegLayerName, &outSegLayerName);
		configModelInterfaces(ClassNet, &inClassLayerName, &outClassLayerName);
		cout << "Segmentation input layer name: " << inSegLayerName << endl;
		cout << "Segmentation output layer name: " << outSegLayerName << endl;
		cout << "Classification input layer name: " << inClassLayerName << endl;
		cout << "Classification output layer name: " << outClassLayerName << endl;
		// 4. Loading model to the device
		SegExcNet = InfEngine.LoadNetwork(SegNet, device);
		ClassExcNet = InfEngine.LoadNetwork(ClassNet, device);
		// 5. Create infer request
		SegInfRequest = SegExcNet.CreateInferRequest();
		ClassInfRequest = ClassExcNet.CreateInferRequest();
		cout << "Press 'q' to exit" << endl;
	}catch(const std::exception & ex){
		cout << "Can't get executable graph: " << ex.what() << endl;
		return -1;
	}
	// Create a window for display.
	namedWindow( "File under test", WINDOW_AUTOSIZE);
	namedWindow( "Predicted data", WINDOW_AUTOSIZE);
	do{
		fileNumber = rand()%filesAvailable;
		fileName = getListFileName(lstFileNames, fileNumber);
		string strFilePath = imageDir + fileName;
		inImage = imread(strFilePath, IMREAD_COLOR);   // Read the file
		if(!inImage.data) {                             // Check for invalid input
			cout <<  "Could not open or find the image" << endl ;
			return -1;
		}
		auto t0 = Time::now();
		// 6. Prepare input
		Blob::Ptr imgBlob = wrapMat2Blob(inImage);  // just wrap Mat data by Blob::Ptr without allocating of new memory
		SegInfRequest.SetBlob(inSegLayerName, imgBlob);  // SegInfRequest accepts input blob of any size
		ClassInfRequest.SetBlob(inClassLayerName, imgBlob);  // SegInfRequest accepts input blob of any size			
		// 7. Do inference
		// Running the request synchronously
		measure(SegInfRequest, "Segmentation");
		measure(ClassInfRequest, "Classification");/**/
		// 8. Process output
		// 8.1 Segmentation
		Blob::Ptr SegOut = SegInfRequest.GetBlob(outSegLayerName);
		size_t inH, inW;
		size_t SegOut_blob_shape_size = SegOut->getTensorDesc().getDims().size();

		if (SegOut_blob_shape_size == 3) {
			inH = imgBlob->getTensorDesc().getDims().at(1);
			inW = imgBlob->getTensorDesc().getDims().at(2);
		} else if (SegOut_blob_shape_size == 4) {
			inH = imgBlob->getTensorDesc().getDims().at(2);
			inW = imgBlob->getTensorDesc().getDims().at(3);
		} else {
			throw std::logic_error("Unexpected SegOut blob shape. Only 4D and 3D SegOut blobs are supported.");
		}
		Mat classPredict = composeClassSeg(SegOut);
		resize(classPredict, classPredict, Size(inW, inH), 0, 0, INTER_NEAREST);
		outImage = inImage.clone();
		colorObjective(outImage, classPredict, Scalar(255, 0, 255), 0.70, 0);
		// 8.2 Classification
		Blob::Ptr ClassOut = ClassInfRequest.GetBlob(outClassLayerName);
		int prdClass = getClass(ClassOut);

		auto t1 = Time::now();
		fsec fs = t1-t0;
		ms d = chrono::duration_cast<ms>(fs);
		cout << endl <<"Full processing duration: " << d.count() << " ms" << endl;
		cout << "Throughput: " << 1000 / d.count() << " FPS" << endl << endl;		

		// 9. Show Data
		float Ecc;
		int Area;
		drawFeatures(outImage, getObjective(classPredict, 0), &Ecc, &Area);
		putText(inImage, fileName, Point(5, 35), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2,8,0);
		putText(inImage, to_string(inH) + 'x' + to_string(inW) + " px", Point(5, 70), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2, 8,0);
		putText(outImage, "Predicted: " + lblClasses[prdClass], Point(5, 35), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2, 8,0);
		putText(outImage, "Area: " + to_string(Area), Point(5, 70), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2, 8,0);
		putText(outImage, "Eccentricity: " + to_string(Ecc), Point(5, 105), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2, 8,0);
		imshow("File under test", inImage );
		imshow("Predicted data", outImage );
	}while(tolower(waitKey(0)) != 'q');//*/
	destroyWindow("File under test");
	destroyWindow("Predicted data");
	return 0;
}

void measure(InferRequest Inference, string id){
	auto t0 = Time::now();
	Inference.Infer();
	auto t1 = Time::now();
	fsec fs = t1-t0;
	ms d = chrono::duration_cast<ms>(fs);
	cout << id << " inference duration: " << d.count() << " ms" << endl;
	cout << "Throughput: " << 1000 / d.count() << " FPS" << endl;
}

void drawFeatures(Mat refImage, Mat binImage, float *Ecc, int *Area){
	Moments mnt = moments(binImage, false);
	*Area = mnt.m00;
	float cx = mnt.m10/mnt.m00;
	float cy = mnt.m01/mnt.m00;
	float angle = atan2(2*mnt.mu11, mnt.mu20-mnt.mu02)/2;
	float a1 = (mnt.mu20 + mnt.mu02 + sqrt(pow(mnt.mu20 - mnt.mu02, 2) + 4*pow(mnt.mu11, 2)));
	float a2 = (mnt.mu20 + mnt.mu02 - sqrt(pow(mnt.mu20 - mnt.mu02, 2) + 4*pow(mnt.mu11, 2)));
	float ra = sqrt(2*a1/mnt.m00);
	float rb = sqrt(2*a2/mnt.m00);
	*Ecc = a1/a2;
	/*float ebx = cos(angle), eby = sin(angle);
	float eax = sin(angle), eay = -cos(angle);
	Size imgSize = binImage.size();
	size_t H = imgSize.height;
	size_t W = imgSize.width;
	float amin = W, amax = 0.0;
	float bmin = H, bmax = 0.0;
	for (size_t w = 0; w < W; w++)
		for (size_t h = 0; h < H; h++)
			if((int)binImage.at<uchar>(h, w)){
				float a = w*eax + h*eay;
				amin = min(amin, a);
				amax = max(amax, a);
				float b = w*ebx + h*eby;
				bmin = min(bmin, b);
				bmax = max(bmax, b);
			}
	Point A(amin*eax + bmin*ebx, amin*eay + bmin*eby);
	Point B(amin*eax + bmax*ebx, amin*eay + bmax*eby);
	Point C(amax*eax + bmax*ebx, amax*eay + bmax*eby);
	Point D(amax*eax + bmin*ebx, amax*eay + bmin*eby);
	line(refImage, A, B, Scalar(0,227,255), 2, LINE_AA);
	line(refImage, B, C, Scalar(217,255,0), 2, LINE_AA);
	line(refImage, C, D, Scalar(0,227,255), 2, LINE_AA);
	line(refImage, D, A, Scalar(217,255,0), 2, LINE_AA);*/

	line(refImage, Point(cx - ra*cos(angle), cy - ra*sin(angle)), Point(cx + ra*cos(angle), cy + ra*sin(angle)), Scalar(0,227,255), 2, LINE_AA);
	angle += CV_PI/2;
	line(refImage, Point(cx - rb*cos(angle), cy - rb*sin(angle)), Point(cx + rb*cos(angle), cy + rb*sin(angle)), Scalar(217,255,0), 2, LINE_AA);
}

void configModelInterfaces(CNNNetwork Model, string *inLayerName, string *outLayerName){
	InputInfo::Ptr ModelInputInfo = Model.getInputsInfo().begin()->second;
	*inLayerName = Model.getInputsInfo().begin()->first;
        ModelInputInfo->setLayout(Layout::NHWC);
        ModelInputInfo->setPrecision(Precision::U8);
	ModelInputInfo->getPreProcess().setResizeAlgorithm(RESIZE_BILINEAR);
	DataPtr ModelOutputInfo = Model.getOutputsInfo().begin()->second;
        *outLayerName = Model.getOutputsInfo().begin()->first;
        ModelOutputInfo->setPrecision(Precision::FP16);
}

CNNNetwork ReadModel(char* modelDir, char *modelName){
	CNNNetReader NetReader;
	NetReader.ReadNetwork(composeFilePath(modelDir, modelName, (char*)".xml"));
	NetReader.ReadWeights(composeFilePath(modelDir, modelName, (char*)".bin"));
        return NetReader.getNetwork();
}

list<string> getFileNames(char* strDirectory){
	list<string> lstFiles;
	DIR *directory;
	struct dirent *element;
	directory = opendir(strDirectory);
	if(directory){
        	while ((element = readdir(directory)) != NULL)
			lstFiles.push_front(element->d_name);
        	closedir(directory);
	}
	return lstFiles;
}

string getListFileName(list<string> FileNames, int index){
	list<string>::iterator FileName = FileNames.begin();
	advance(FileName, index);
	return *FileName;
}

char* getDirectory(char** argv, int value){
	int intPathLen = strlen(*(argv + value));
	char *chrPath = (char*)malloc(sizeof(char)*(intPathLen + 2));
	strcpy(chrPath, *(argv + value));
	*(chrPath + intPathLen) = '/';
	*(chrPath + intPathLen + 1) = '\0';
	return chrPath;
}

char* composeFilePath(char* path, char* file, char* ext){
	int intPathLen = strlen(path);
	int intFileLen = strlen(file);
	int intExtLen = strlen(ext);
	int fullPathLen = intPathLen + intFileLen + intExtLen;
	char *ptrFullPath = (char*)malloc(sizeof(char)*(fullPathLen + 1));
	strcpy(ptrFullPath, path);
	strcpy(ptrFullPath + intPathLen, file);
	strcpy(ptrFullPath + intPathLen + intFileLen, ext);
	*(ptrFullPath + intPathLen + intFileLen + intExtLen) = '\0';
	return ptrFullPath;
}

Mat composeClassSeg(Blob::Ptr ptrBlobProb){
	const auto output_data = ptrBlobProb->buffer().as<float*>();
        size_t C, H, W;
	size_t output_blob_shape_size = ptrBlobProb->getTensorDesc().getDims().size();

	if (output_blob_shape_size == 3) {
		C = 1;
		H = ptrBlobProb->getTensorDesc().getDims().at(1);
		W = ptrBlobProb->getTensorDesc().getDims().at(2);
        } else if (output_blob_shape_size == 4) {
		C = ptrBlobProb->getTensorDesc().getDims().at(1);
		H = ptrBlobProb->getTensorDesc().getDims().at(2);
		W = ptrBlobProb->getTensorDesc().getDims().at(3);
        } else {
		throw std::logic_error("Unexpected output blob shape. Only 4D and 3D output blobs are supported.");
        }
	Mat classMat(H, W, CV_8UC1, Scalar(0, 0, 0));
	vector<vector<size_t>> classArray(H, vector<size_t>(W, 0));
	vector<vector<float>> probArray(H, vector<float>(W, 0.));
	for (size_t w = 0; w < W; w++)
		for (size_t h = 0; h < H; h++)
			if (C == 1)
				classArray[h][w] = static_cast<size_t>(output_data[W * h + w]);
			else
				for (size_t classID = 0; classID < C; classID++) {
					auto data = output_data[W * H * classID + W * h + w];
					if (data > probArray[h][w]) {
						classArray[h][w] = classID;
						probArray[h][w] = data;
						classMat.at<uchar>(h,w) = classID;
					}
				}
	return classMat;
}

Mat colorObjective(Mat imageMat, Mat classMat, Scalar colorMask, float alpha, int objetive){
	size_t H = classMat.rows, W = classMat.cols;
	Vec3b pixelData;
	for (size_t w = 0; w < W; w++)
		for (size_t h = 0; h < H; h++)
			if(classMat.at<uchar>(h, w) == objetive){
				pixelData = imageMat.at<Vec3b>(h, w);
				pixelData[0] = pixelData[0]*alpha + colorMask[0]*(1-alpha);
				pixelData[1] = pixelData[1]*alpha + colorMask[1]*(1-alpha);
				pixelData[2] = pixelData[2]*alpha + colorMask[2]*(1-alpha);
				imageMat.at<Vec3b>(h, w) = pixelData;
			}
	return imageMat;
}

Mat getObjective(Mat Classes, int obj){
	Size imgSize = Classes.size();
	Mat classMask(imgSize, CV_8UC1, Scalar(0));
	size_t H = imgSize.height;
	size_t W = imgSize.width;
	for (size_t w = 0; w < W; w++)
		for (size_t h = 0; h < H; h++)
			classMask.at<uchar>(h, w) = (Classes.at<uchar>(h, w) == obj);
	return classMask;
}

int getClass(Blob::Ptr ptrBlobProb){
	size_t ClassOut_size = ptrBlobProb->getTensorDesc().getDims().at(1);
	const auto output_data = ptrBlobProb->buffer().as<float*>();
	int classID = 0;
	float ptr = 0;
	for (size_t prob = 0; prob < ClassOut_size; prob++){
		auto data = output_data[prob];
		if(data > ptr){
			classID = prob;
			ptr = data;
		}
	}
	return classID;
}

static UNUSED Blob::Ptr wrapMat2Blob(const Mat &mat) {
    size_t channels = mat.channels();
    size_t height = mat.size().height;
    size_t width = mat.size().width;

    size_t strideH = mat.step.buf[0];
    size_t strideW = mat.step.buf[1];

    bool is_dense =
            strideW == channels &&
            strideH == channels * width;

    if (!is_dense) THROW_IE_EXCEPTION
                << "Doesn't support conversion from not dense cv::Mat";

    TensorDesc tDesc(Precision::U8, {1, channels, height, width}, Layout::NHWC);

    return make_shared_blob<uint8_t>(tDesc, mat.data);
}
