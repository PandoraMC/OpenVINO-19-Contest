#include <dirent.h>
#include <iostream>
#include <ctype.h>
#include <opencv2/core.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <iterator>
#include <time.h>
#include <stdlib.h>
#include <vector>
#include <memory>
#include <string>
#include <samples/common.hpp>
#include <math.h>

#include <inference_engine.hpp>
#include <ext_list.hpp>
#include <samples/ocv_common.hpp>

#define DIR_OFFSET 2

using namespace cv;
using namespace std;
using namespace InferenceEngine;

list<string> getFileNames(char* strDirectory);
void configModelInterfaces(CNNNetwork Model, string *inLayerName, string *outLayerName);
CNNNetwork ReadModel(char* modelDir, char *modelName);
string getListFileName(list<string> FileNames, int index);
char* getDirectory(char** argv, int value);
char* composeFilePath(char* path, char* file, char* ext);
Mat composeClassSeg(Blob::Ptr ptrBlobProb);
Mat colorObjective(Mat imageMat, Mat classMat, Scalar colorMask, float alpha, int objetive);
int getClass(Blob::Ptr ptrBlobProb);
string lblClasses[3] = {"Common Nevus", "Atypical Nevus", "Melanoma"};

int main(int argc, char** argv){
	srand(time(NULL));
	int fileNumber, filesAvailable;
	string inSegLayerName, inClassLayerName, outSegLayerName, outClassLayerName;
	string fileName;
	char *imageDir = getDirectory(argv, 1);
	list<string> lstFileNames = getFileNames(imageDir);
	filesAvailable = lstFileNames.size() - DIR_OFFSET;
	cout << "Image directory " << imageDir << " with " << filesAvailable << " files available" << endl;
	char *modelDir = getDirectory(argv, 2);
	char *SegModelName = *(argv + 3);
	char *ClassModelName = *(argv + 4);
	string device = *(argv + 5);
	cout << "Segmentation model path: " << modelDir << SegModelName << ".*" << endl;	
	cout << "Classification model path: " << modelDir << ClassModelName << ".*" << endl;
	// 1. Load inference Engine instance
	Core InfEngine;
	if(!device.compare("CPU"))
		InfEngine.AddExtension(make_shared<Extensions::Cpu::CpuExtensions>(), "CPU");
	cout << "Device:" << endl << InfEngine.GetVersions(device) << endl;
	// 2. Read IR Generated by ModelOptimizer (.xml and .bin files)
	CNNNetwork SegNet = ReadModel(modelDir, SegModelName);	
	CNNNetwork ClassNet = ReadModel(modelDir, ClassModelName);
	// 3. Configure input & output
	// 3.1 Input configuration. Mark input as resizable by setting of a resize algorithm.
        // In this case we will be able to set an input blob of any shape to an infer request.
        // Resize and layout conversions are executed automatically during inference

	configModelInterfaces(SegNet, &inSegLayerName, &outSegLayerName);
	configModelInterfaces(ClassNet, &inClassLayerName, &outClassLayerName);
	cout << "Segmentation input layer name: " << inSegLayerName << endl;
	cout << "Segmentation output layer name: " << outSegLayerName << endl;
	cout << "Classification input layer name: " << inClassLayerName << endl;
	cout << "Classification output layer name: " << outClassLayerName << endl;

	// 4. Loading model to the device
	ExecutableNetwork SegExcNet = InfEngine.LoadNetwork(SegNet, device);
	ExecutableNetwork ClassExcNet = InfEngine.LoadNetwork(ClassNet, device);
	// 5. Create infer request
	InferRequest SegInfRequest = SegExcNet.CreateInferRequest();
	InferRequest ClassInfRequest = ClassExcNet.CreateInferRequest();
/*/-------------------------------------------------------------------------------------------------
	
	// Returns a pseudo-random integer between 0 and RAND_MAX.
	fileNumber = rand()%filesAvailable;//OK
	cout << fileNumber << "/" << filesAvailable <<endl;
	// Get file in 'fileNumber'
	fileName = getListFileName(lstFileNames, fileNumber);
	// Compose the full file path
	
	string strFilePath = imageDir + fileName;
	cout << imageDir + fileName<<endl;
	// 6. Prepare input
	// Read input image to a blob and set it to an infer request without resize and layout conversions.
        Mat image = imread(strFilePath);
	//resize(image, image, Size(320, 160), 0, 0, INTER_LINEAR);
        Blob::Ptr imgBlob = wrapMat2Blob(image);  // just wrap Mat data by Blob::Ptr without allocating of new memory
        SegInfRequest.SetBlob(inSegLayerName, imgBlob);  // SegInfRequest accepts input blob of any size
	// 7. Do inference
	// Running the request synchronously
        SegInfRequest.Infer();
	// 8. Process output
	Blob::Ptr output = SegInfRequest.GetBlob(outSegLayerName);
	size_t inH, inW;
	size_t output_blob_shape_size = output->getTensorDesc().getDims().size();
	cout << "Blob size " << output_blob_shape_size << endl;

	if (output_blob_shape_size == 3) {
		inH = imgBlob->getTensorDesc().getDims().at(1);
		inW = imgBlob->getTensorDesc().getDims().at(2);
        } else if (output_blob_shape_size == 4) {
		inH = imgBlob->getTensorDesc().getDims().at(2);
		inW = imgBlob->getTensorDesc().getDims().at(3);
        } else {
		throw std::logic_error("Unexpected output blob shape. Only 4D and 3D output blobs are supported.");
        }


	// Dump resulting image 
	//string outfileName = "/media/anubis/Data/OpenVINO/ModelImplementation/out" + fileName;
	//ofstream outFile(outfileName, ofstream::binary);
	//if (!outFile.is_open())
	//	throw logic_error("Can't open file : " + outfileName);

	//writeOutputBmp(outArrayClasses, C, outFile);

	Mat img = composeClassSeg(output);

	cvtColor(img, img, COLOR_BGR2RGB);

	size_t input_blob_shape_size = imgBlob->getTensorDesc().getDims().size();
	cout << "Blob size " << input_blob_shape_size << endl;

	resize(img, img, Size(inW, inH), 0, 0, INTER_LINEAR);
	multiply(image, img, image);

	namedWindow(fileName, WINDOW_AUTOSIZE);
	imshow(fileName, image);
	waitKey(0);
	destroyWindow(fileName);     // */
	
	printf("Press 'q' to exit\n");
	// Create a window for display.
	namedWindow( "File under test", WINDOW_AUTOSIZE);
	namedWindow( "Predicted data", WINDOW_AUTOSIZE);
	do{
		// Returns a pseudo-random integer between 0 and RAND_MAX.
		fileNumber = rand()%filesAvailable;//OK
		// Get file in 'fileNumber'
		fileName = getListFileName(lstFileNames, fileNumber);
		// Compose the full file path
		string strFilePath = imageDir + fileName;
		Mat inImage;
		inImage = imread(strFilePath, IMREAD_COLOR);   // Read the file
		if(!inImage.data) {                             // Check for invalid input
			cout <<  "Could not open or find the image" << endl ;
			return -1;
		}
		// 6. Prepare input
		Blob::Ptr imgBlob = wrapMat2Blob(inImage);  // just wrap Mat data by Blob::Ptr without allocating of new memory
		SegInfRequest.SetBlob(inSegLayerName, imgBlob);  // SegInfRequest accepts input blob of any size
		ClassInfRequest.SetBlob(inClassLayerName, imgBlob);  // SegInfRequest accepts input blob of any size			
		// 7. Do inference
		// Running the request synchronously
		SegInfRequest.Infer();
		ClassInfRequest.Infer();					
		// 8. Process output
		// 8.1 Segmentation
		Blob::Ptr SegOut = SegInfRequest.GetBlob(outSegLayerName);
		size_t inH, inW;
		size_t SegOut_blob_shape_size = SegOut->getTensorDesc().getDims().size();

		if (SegOut_blob_shape_size == 3) {
			inH = imgBlob->getTensorDesc().getDims().at(1);
			inW = imgBlob->getTensorDesc().getDims().at(2);
		} else if (SegOut_blob_shape_size == 4) {
			inH = imgBlob->getTensorDesc().getDims().at(2);
			inW = imgBlob->getTensorDesc().getDims().at(3);
		} else {
			throw std::logic_error("Unexpected SegOut blob shape. Only 4D and 3D SegOut blobs are supported.");
		}

		Mat classPredict = composeClassSeg(SegOut);
		resize(classPredict, classPredict, Size(inW, inH), 0, 0, INTER_NEAREST);

		Mat outImage = inImage.clone();
		colorObjective(outImage, classPredict, Scalar(255, 0, 255), 0.70, 0);
		// 8.2 Classification
		Blob::Ptr ClassOut = ClassInfRequest.GetBlob(outClassLayerName);
		int prdClass = getClass(ClassOut);
		// 9. Show Data
		putText(inImage, fileName, Point(5, 35), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2,8,0);
		putText(inImage, to_string(inH) + 'x' + to_string(inW) + " px", Point(5, 65), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2, 8,0);
		putText(outImage, "Predicted: " + lblClasses[prdClass], Point(5, 35), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2, 8,0);
		imshow("File under test", inImage );
		imshow("Predicted data", outImage );

	}while(tolower(waitKey(0)) != 'q');//*/
	destroyWindow("File under test");
	destroyWindow("Predicted data");
	return 0;
}

void configModelInterfaces(CNNNetwork Model, string *inLayerName, string *outLayerName){
	InputInfo::Ptr ModelInputInfo = Model.getInputsInfo().begin()->second;
	*inLayerName = Model.getInputsInfo().begin()->first;
        ModelInputInfo->setLayout(Layout::NHWC);
        ModelInputInfo->setPrecision(Precision::U8);
	ModelInputInfo->getPreProcess().setResizeAlgorithm(RESIZE_BILINEAR);
	DataPtr ModelOutputInfo = Model.getOutputsInfo().begin()->second;
        *outLayerName = Model.getOutputsInfo().begin()->first;
        ModelOutputInfo->setPrecision(Precision::FP32);
}

CNNNetwork ReadModel(char* modelDir, char *modelName){
	CNNNetReader NetReader;
	NetReader.ReadNetwork(composeFilePath(modelDir, modelName, (char*)".xml"));
	NetReader.ReadWeights(composeFilePath(modelDir, modelName, (char*)".bin"));
        return NetReader.getNetwork();
}

list<string> getFileNames(char* strDirectory){
	list<string> lstFiles;
	DIR *directory;
	struct dirent *element;
	directory = opendir(strDirectory);
	if(directory){
        	while ((element = readdir(directory)) != NULL)
			lstFiles.push_front(element->d_name);
        	closedir(directory);
	}
	return lstFiles;
}

string getListFileName(list<string> FileNames, int index){
	list<string>::iterator FileName = FileNames.begin();
	advance(FileName, index);
	return *FileName;
}

char* getDirectory(char** argv, int value){
	int intPathLen = strlen(*(argv + value));
	char *chrPath = (char*)malloc(sizeof(char)*(intPathLen + 2));
	strcpy(chrPath, *(argv + value));
	*(chrPath + intPathLen) = '/';
	*(chrPath + intPathLen + 1) = '\0';
	return chrPath;
}

char* composeFilePath(char* path, char* file, char* ext){
	int intPathLen = strlen(path);
	int intFileLen = strlen(file);
	int intExtLen = strlen(ext);
	int fullPathLen = intPathLen + intFileLen + intExtLen;
	char *ptrFullPath = (char*)malloc(sizeof(char)*(fullPathLen + 1));
	strcpy(ptrFullPath, path);
	strcpy(ptrFullPath + intPathLen, file);
	strcpy(ptrFullPath + intPathLen + intFileLen, ext);
	*(ptrFullPath + intPathLen + intFileLen + intExtLen) = '\0';
	return ptrFullPath;
}

Mat composeClassSeg(Blob::Ptr ptrBlobProb){
	const auto output_data = ptrBlobProb->buffer().as<float*>();
        size_t C, H, W;
	size_t output_blob_shape_size = ptrBlobProb->getTensorDesc().getDims().size();

	if (output_blob_shape_size == 3) {
		C = 1;
		H = ptrBlobProb->getTensorDesc().getDims().at(1);
		W = ptrBlobProb->getTensorDesc().getDims().at(2);
        } else if (output_blob_shape_size == 4) {
		C = ptrBlobProb->getTensorDesc().getDims().at(1);
		H = ptrBlobProb->getTensorDesc().getDims().at(2);
		W = ptrBlobProb->getTensorDesc().getDims().at(3);
        } else {
		throw std::logic_error("Unexpected output blob shape. Only 4D and 3D output blobs are supported.");
        }

	Mat classMat(H, W, CV_8UC1, Scalar(0, 0, 0));
	// This vector stores pixels classes 
	vector<vector<size_t>> classArray(H, vector<size_t>(W, 0));
	vector<vector<float>> probArray(H, vector<float>(W, 0.));
	// Iterating over each pixel **
	for (size_t w = 0; w < W; w++)
		for (size_t h = 0; h < H; h++)
			// number of channels = 1 means that the output is already ArgMax'ed *
			if (C == 1)
				classArray[h][w] = static_cast<size_t>(output_data[W * h + w]);
			else
				// Iterating over each class probability 
				for (size_t ch = 0; ch < C; ch++) {
					auto data = output_data[W * H * ch + W * h + w];
					if (data > probArray[h][w]) {
						classArray[h][w] = ch;
						probArray[h][w] = data;
						classMat.at<uchar>(h,w) = ch;
					}
				}
	return classMat;
}

Mat colorObjective(Mat imageMat, Mat classMat, Scalar colorMask, float alpha, int objetive){
	size_t H = classMat.rows, W = classMat.cols;
	Vec3b pixelData;
	for (size_t w = 0; w < W; w++)
		for (size_t h = 0; h < H; h++)
			if(classMat.at<uchar>(h, w) == objetive){
				pixelData = imageMat.at<Vec3b>(h, w);
				pixelData[0] = pixelData[0]*alpha + colorMask[0]*(1-alpha);
				pixelData[1] = pixelData[1]*alpha + colorMask[1]*(1-alpha);
				pixelData[2] = pixelData[2]*alpha + colorMask[2]*(1-alpha);
				imageMat.at<Vec3b>(h, w) = pixelData;
			}
	return imageMat;
}

int getClass(Blob::Ptr ptrBlobProb){
	size_t ClassOut_size = ptrBlobProb->getTensorDesc().getDims().at(1);
	const auto output_data = ptrBlobProb->buffer().as<float*>();
	int classID = 0;
	float ptr = 0;
	for (size_t prob = 0; prob < ClassOut_size; prob++){
		auto data = output_data[prob];
		//probArray[prob] = data;
		//cout << "pos: " << prob << "; data: " << data <<"; ";
		if(data > ptr){
			classID = prob;
			ptr = data;
		}
	}
	//cout << endl;
	return classID;
}
