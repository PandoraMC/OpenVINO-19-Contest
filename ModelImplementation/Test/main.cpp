#include <dirent.h>
#include <iostream>
#include <ctype.h>
#include <opencv2/core.hpp>
#include <opencv2/imgproc.hpp>
#include <opencv2/highgui/highgui.hpp>
#include <iterator>
#include <time.h>
#include <stdlib.h>
#include <vector>
#include <memory>
#include <string>
#include <samples/common.hpp>
#include <math.h>
#include "ImageProcessor.h"
#include "StringHandler.h"

#include <inference_engine.hpp>
#include <ext_list.hpp>

#define DIR_OFFSET 2

using namespace cv;
using namespace std;
using namespace InferenceEngine;

typedef chrono::high_resolution_clock Time;
typedef chrono::duration<double, ratio<1, 1000>> ms;
typedef chrono::duration<float> fsec;

void configModelInterfaces(CNNNetwork Model, string *inLayerName, string *outLayerName);
CNNNetwork ReadModel(char* modelDir, char *modelName);
void measure(InferRequest Infer, string id);
static UNUSED Blob::Ptr wrapMat2Blob(const Mat &mat);


int main(int argc, char** argv){
	string lblClasses[3] = {"Common Nevus", "Atypical Nevus", "Melanoma"};
	int fileNumber, filesAvailable;
	string fileName, inSegLayerName, inClassLayerName, outSegLayerName, outClassLayerName;
	srand(time(NULL));
	char *imageDir = getDirectory(argv, 1);
	list<string> lstFileNames = getFileNames(imageDir);
	filesAvailable = lstFileNames.size() - DIR_OFFSET;
	cout << "Image directory " << imageDir << " with " << filesAvailable << " files available" << endl;
	char *modelDir = getDirectory(argv, 2);
	char *SegModelName = *(argv + 3);
	char *ClassModelName = *(argv + 4);
	string device = *(argv + 5);
	Mat inImage, outImage;
	cout << "Segmentation model path: " << modelDir << SegModelName << ".*" << endl;	
	cout << "Classification model path: " << modelDir << ClassModelName << ".*" << endl;
	// 1. Load inference Engine instance
	Core InfEngine;
	CNNNetwork SegNet, ClassNet;
	ExecutableNetwork SegExcNet, ClassExcNet;
	InferRequest SegInfRequest, ClassInfRequest;
	try{
		
		if(!device.compare("CPU"))
			InfEngine.AddExtension(make_shared<Extensions::Cpu::CpuExtensions>(), "CPU");
		cout << "Device:" << endl << InfEngine.GetVersions(device) << endl;
		// 2. Read IR Generated by ModelOptimizer (.xml and .bin files)
		SegNet = ReadModel(modelDir, SegModelName);	
		ClassNet = ReadModel(modelDir, ClassModelName);

		QueryNetworkResult SegRes = InfEngine.QueryNetwork(SegNet, device, { });
		QueryNetworkResult ClassRes = InfEngine.QueryNetwork(ClassNet, device, { });

		SegRes.supportedLayersMap["layerName"] = "CPU";
		ClassRes.supportedLayersMap["layerName"] = "CPU";
		cout << endl << "[Segmentation architecture]" << endl;
		for (auto && layer : SegRes.supportedLayersMap)
			if(layer.first.compare("layerName")){
				SegNet.getLayerByName(layer.first.c_str())->affinity = layer.second;
				cout << layer.first << "; " << SegNet.getLayerByName(layer.first.c_str())->affinity << endl;
			}
		cout << endl << "[Classification architecture]" << endl;
		for (auto && layer : ClassRes.supportedLayersMap)
			if(layer.first.compare("layerName")){
				ClassNet.getLayerByName(layer.first.c_str())->affinity = layer.second;
				cout << layer.first << "; " << ClassNet.getLayerByName(layer.first.c_str())->affinity << endl;
			}
		// 3. Configure input & output
		// 3.1 Input configuration. Mark input as resizable by setting of a resize algorithm.
		configModelInterfaces(SegNet, &inSegLayerName, &outSegLayerName);
		configModelInterfaces(ClassNet, &inClassLayerName, &outClassLayerName);
		cout << endl << "Segmentation input layer name: " << inSegLayerName << endl;
		cout << "Segmentation output layer name: " << outSegLayerName << endl;
		cout << "Classification input layer name: " << inClassLayerName << endl;
		cout << "Classification output layer name: " << outClassLayerName << endl;
		// 4. Loading model to the device
		SegExcNet = InfEngine.LoadNetwork(SegNet, device);
		ClassExcNet = InfEngine.LoadNetwork(ClassNet, device);
		// 5. Create infer request
		SegInfRequest = SegExcNet.CreateInferRequest();
		ClassInfRequest = ClassExcNet.CreateInferRequest();
		cout << "Press 'q' to exit" << endl;
	}catch(const std::exception & ex){
		cout << "Can't get executable graph: " << ex.what() << endl;
		return -1;
	}
	// Create a window for display.
	namedWindow( "File under test", WINDOW_AUTOSIZE);
	namedWindow( "Predicted data", WINDOW_AUTOSIZE);
	do{
		fileNumber = rand()%filesAvailable;
		fileName = getListFileName(lstFileNames, fileNumber);
		string strFilePath = imageDir + fileName;
		inImage = imread(strFilePath, IMREAD_COLOR);   // Read the file
		if(!inImage.data) {                             // Check for invalid input
			cout <<  "Could not open or find the image" << endl ;
			return -1;
		}
		auto t0 = Time::now();
		// 6. Prepare input
		Blob::Ptr imgBlob = wrapMat2Blob(inImage);  // just wrap Mat data by Blob::Ptr without allocating of new memory
		SegInfRequest.SetBlob(inSegLayerName, imgBlob);  // SegInfRequest accepts input blob of any size
		ClassInfRequest.SetBlob(inClassLayerName, imgBlob);  // SegInfRequest accepts input blob of any size			
		// 7. Do inference
		// Running the request synchronously
		measure(SegInfRequest, "Segmentation");
		measure(ClassInfRequest, "Classification");/**/
		// 8. Process output
		// 8.1 Segmentation
		Blob::Ptr SegOut = SegInfRequest.GetBlob(outSegLayerName);
		size_t inH, inW;
		size_t SegOut_blob_shape_size = SegOut->getTensorDesc().getDims().size();

		if (SegOut_blob_shape_size == 3) {
			inH = imgBlob->getTensorDesc().getDims().at(1);
			inW = imgBlob->getTensorDesc().getDims().at(2);
		} else if (SegOut_blob_shape_size == 4) {
			inH = imgBlob->getTensorDesc().getDims().at(2);
			inW = imgBlob->getTensorDesc().getDims().at(3);
		} else {
			throw std::logic_error("Unexpected SegOut blob shape. Only 4D and 3D SegOut blobs are supported.");
		}
		Mat classPredict = composeClassSeg(SegOut);
		resize(classPredict, classPredict, Size(inW, inH), 0, 0, INTER_NEAREST);
		outImage = inImage.clone();
		colorObjective(outImage, classPredict, Scalar(255, 0, 255), 0.70, 0);
		// 8.2 Classification
		Blob::Ptr ClassOut = ClassInfRequest.GetBlob(outClassLayerName);
		int prdClass = getClass(ClassOut);

		auto t1 = Time::now();
		fsec fs = t1-t0;
		ms d = chrono::duration_cast<ms>(fs);
		cout << endl <<"Full processing duration: " << d.count() << " ms" << endl;
		cout << "Throughput: " << 1000 / d.count() << " FPS" << endl << endl;		

		// 9. Show Data
		float Ecc;
		int Area;
		drawFeatures(outImage, getObjective(classPredict, 0), &Ecc, &Area);
		putText(inImage, fileName, Point(5, 35), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2,8,0);
		putText(inImage, to_string(inH) + 'x' + to_string(inW) + " px", Point(5, 70), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2, 8,0);
		putText(outImage, "Predicted: " + lblClasses[prdClass], Point(5, 35), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2, 8,0);
		putText(outImage, "Area: " + to_string(Area), Point(5, 70), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2, 8,0);
		putText(outImage, "Eccentricity: " + to_string(Ecc), Point(5, 105), FONT_HERSHEY_DUPLEX, 1, Scalar(255, 255, 255), 2, 8,0);
		imshow("File under test", inImage );
		imshow("Predicted data", outImage );
	}while(tolower(waitKey(0)) != 'q');//*/
	destroyWindow("File under test");
	destroyWindow("Predicted data");
	return 0;
}

void measure(InferRequest Inference, string id){
	auto t0 = Time::now();
	Inference.Infer();
	auto t1 = Time::now();
	fsec fs = t1-t0;
	ms d = chrono::duration_cast<ms>(fs);
	cout << id << " inference duration: " << d.count() << " ms" << endl;
	cout << "Throughput: " << 1000/d.count() << " FPS" << endl;
}

void configModelInterfaces(CNNNetwork Model, string *inLayerName, string *outLayerName){
	InputInfo::Ptr ModelInputInfo = Model.getInputsInfo().begin()->second;
	*inLayerName = Model.getInputsInfo().begin()->first;
        ModelInputInfo->setLayout(Layout::NHWC);
        ModelInputInfo->setPrecision(Precision::U8);
	ModelInputInfo->getPreProcess().setResizeAlgorithm(RESIZE_BILINEAR);
	DataPtr ModelOutputInfo = Model.getOutputsInfo().begin()->second;
        *outLayerName = Model.getOutputsInfo().begin()->first;
        ModelOutputInfo->setPrecision(Precision::FP16);
}

CNNNetwork ReadModel(char* modelDir, char *modelName){
	CNNNetReader NetReader;
	NetReader.ReadNetwork(composeFilePath(modelDir, modelName, (char*)".xml"));
	NetReader.ReadWeights(composeFilePath(modelDir, modelName, (char*)".bin"));
        return NetReader.getNetwork();
}

static UNUSED Blob::Ptr wrapMat2Blob(const Mat &mat) {
    size_t channels = mat.channels();
    size_t height = mat.size().height;
    size_t width = mat.size().width;

    size_t strideH = mat.step.buf[0];
    size_t strideW = mat.step.buf[1];

    bool is_dense =
            strideW == channels &&
            strideH == channels * width;

    if (!is_dense) THROW_IE_EXCEPTION
                << "Doesn't support conversion from not dense cv::Mat";

    TensorDesc tDesc(Precision::U8, {1, channels, height, width}, Layout::NHWC);

    return make_shared_blob<uint8_t>(tDesc, mat.data);
}
